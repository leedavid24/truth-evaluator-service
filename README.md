# Truth Evaluation Microservice

## Description
The truth evaluation microservice allows users to validate claims based on its authenticity. This services uses embedded Generative AI and LLM models to predict claims and give a confidence score based on it.

## Getting Started

This program uses pre-trained models from [Hugging Face](https://huggingface.co/). Depending on the model's used it may require significant storage and computational power, its advised to look at specific model requirements before using them.

The default models used are [facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli) for zero-shot classification and [google/flan-t5-base](https://huggingface.co/google/flan-t5-base) for reasoning and text generation.


### Prerequisites
-   Python Version 3.11 or less (`distutils` is not supported on 3.12)
-   8 GB of RAM or higher (if running models locally)
-   8 to 12 GB of free space (depending on the size of the model specified)
-   (optional) A dedicated GPU with VRAM (for larger models)

### Setting up the Service
1. Clone the repository using `git clone https://github.com/leedavid24/truth-evaluator-service.git`
2. Navigate to the root directory `truth-evaluator-service`
3. (optional) Create a virtual venv in the console: `python3 -m venv venv`
4. Run `pip install -r requirements.txt`
5. Configure a `.env` file with the following attributes:
   
    | Attribute          | Default                    | Description                                                                        |
    | ------------------ | -------------------------- |------------------------------------------------------------------------------------|
    | `HOST`             | `localhost`                | The host for the server.                                                           |
    | `PORT`             | 8000                       | The port the server will run on.                                                   |
    | `PREDICTION_MODEL` | `facebook/bart-large-mnli` | The model type used of classifying statements and determining the confidence score. |
    | `REASONING_MODEL` | `google/flan-t5-base`      | The reasoning model to use for determining the reason of claims.                   |


6. Run `python -m main.py`

### How to Request Data

#### Validate a Claim: POST `${HOST}:${PORT}/truth-evaluator-service/validate`

| Attribute | Type | Required | Description | Example |
|-----------|------|----------|-------------|---------|


### How to Receive Data

#### POST RESPONSE `${HOST}:${PORT}/truth-evaluator-service/validate`

HTTP 200 (Response Body Attributes):
| Attribute | Type | Description | 
|-----------|------|------------|
| confidence         |   string   | The confidence score generated by the LLM between 0 and 100.
| rating | string       | The models rating based on the confidence score and claim, can be `true`, `false`, or `unverified`
| reason | string | The reason generated by the generative AI model.

Example:
```
{
  "confidence": 65,
  "rating": "true",
  "reason": "Paris is a city in France. The answer is yes."
}
```
| Attribute | Type   | Description                                                                   | 
|-----------|--------|-------------------------------------------------------------------------------|
| reason    | string | The reason for the HTTP status code (invalid claim parameter type or missing) |

HTTP 400 (Response Body Attributes):

Example:
```
{
  "reason": "Invalid parameter ‘claim’ is given or missing."
}
```

HTTP 500 (Response Body Attributes):
| Attribute | Type | Description | 
|-----------|------|------------|
| reason | string | The reason for the HTTP status code (service exception)

Example:
```
{
  "reason": "Service not available"
}
```

## UML Sequence Diagram